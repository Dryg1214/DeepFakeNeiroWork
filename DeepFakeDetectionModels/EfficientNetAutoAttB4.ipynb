{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Ob4IS5MDoyGa"
      },
      "source": [
        "# Video Face Manipulation Detection Through Ensemble of CNNs\n",
        "Image and Sound Processing Lab - Politecnico di Milano\n",
        "- NicolÃ² Bonettini\n",
        "- Edoardo Daniele Cannas\n",
        "- Sara Mandelli\n",
        "- Luca Bondi\n",
        "- Paolo Bestagini\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO59OMpjrK8f"
      },
      "source": [
        "!git clone https://github.com/polimi-ispl/icpr2020dfdc\n",
        "!pip install efficientnet-pytorch\n",
        "!pip install -U git+https://github.com/albu/albumentations > /dev/null\n",
        "!cd icpr2020dfdc/notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xIVvWj0oyGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "099e901b-d247-4f92-b900-ef7265c625e2"
      },
      "source": [
        "import torch\n",
        "from torch.utils.model_zoo import load_url\n",
        "from torchvision.transforms import ToPILImage\n",
        "from PIL import Image, ImageChops\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from blazeface import FaceExtractor, BlazeFace\n",
        "from architectures import fornet,weights\n",
        "from isplutils import utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-86b4f1606a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mblazeface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaceExtractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlazeFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marchitectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfornet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0misplutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'blazeface'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYkG7citoyGi"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJZZHVtoyGj"
      },
      "source": [
        "\"\"\"\n",
        "Choose an architecture between\n",
        "- EfficientNetAutoAttB4\n",
        "- EfficientNetAutoAttB4ST\n",
        "- Xception\n",
        "\"\"\"\n",
        "net_model = 'EfficientNetAutoAttB4'\n",
        "\n",
        "\"\"\"\n",
        "Choose a training dataset between\n",
        "- DFDC\n",
        "- FFPP\n",
        "\"\"\"\n",
        "train_db = 'DFDC'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiAW05h0oyGk"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "face_policy = 'scale'\n",
        "face_size = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1qTpFUzoyGl"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp14nU6RoyGl"
      },
      "source": [
        "model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n",
        "net = getattr(fornet,net_model)().eval().to(device)\n",
        "net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiqEFNDjoyGn"
      },
      "source": [
        "transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMSLQ-V3oyGn"
      },
      "source": [
        "facedet = BlazeFace().to(device)\n",
        "facedet.load_weights(\"../blazeface/blazeface.pth\")\n",
        "facedet.load_anchors(\"../blazeface/anchors.npy\")\n",
        "face_extractor = FaceExtractor(facedet=facedet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox1QFOOJoyGo"
      },
      "source": [
        "## Load images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Qqqj4loyGo"
      },
      "source": [
        "im_real = Image.open('samples/lynaeydofd_fr0.jpg')\n",
        "im_fake = Image.open('samples/mqzvfufzoq_fr0.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjCCM0WpoyGq"
      },
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(12,4))\n",
        "\n",
        "ax[0].imshow(im_real)\n",
        "ax[0].set_title('REAL')\n",
        "\n",
        "ax[1].imshow(im_fake)\n",
        "ax[1].set_title('FAKE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZilpjCtboyGq"
      },
      "source": [
        "## Extract faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEhqctNwoyGr"
      },
      "source": [
        "im_real_faces = face_extractor.process_image(img=im_real)\n",
        "im_fake_faces = face_extractor.process_image(img=im_fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGmEN4VDoyGr"
      },
      "source": [
        "im_real_face = im_real_faces['faces'][0] # take the face with the highest confidence score found by BlazeFace\n",
        "im_fake_face = im_fake_faces['faces'][0] # take the face with the highest confidence score found by BlazeFace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5-WgXLoyGr"
      },
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
        "\n",
        "ax[0].imshow(im_real_face)\n",
        "ax[0].set_title('REAL')\n",
        "\n",
        "ax[1].imshow(im_fake_face)\n",
        "ax[1].set_title('FAKE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbcf9O5IoyGs"
      },
      "source": [
        "## Predict scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GuUXGWdoyGs"
      },
      "source": [
        "faces_t = torch.stack( [ transf(image=im)['image'] for im in [im_real_face,im_fake_face] ] )\n",
        "\n",
        "with torch.no_grad():\n",
        "    faces_pred = torch.sigmoid(net(faces_t.to(device))).cpu().numpy().flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxNrw9royGt"
      },
      "source": [
        "\"\"\"\n",
        "Print scores.\n",
        "A score close to 0 predicts REAL. A score close to 1 predicts FAKE.\n",
        "\"\"\"\n",
        "print('Score for REAL face: {:.4f}'.format(faces_pred[0]))\n",
        "print('Score for FAKE face: {:.4f}'.format(faces_pred[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCY16BetoyGt"
      },
      "source": [
        "##Â Get attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZAHAa6JoyGt"
      },
      "source": [
        "faces_t = torch.stack( [ transf(image=im)['image'] for im in [im_real_face,im_fake_face] ] )\n",
        "\n",
        "with torch.no_grad():\n",
        "    if hasattr(net,'feat_ext'):\n",
        "        atts = net.feat_ext.get_attention(faces_t.to(device)).cpu()\n",
        "    else:\n",
        "        atts = net.get_attention(faces_t.to(device)).cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCetWOaWoyGu"
      },
      "source": [
        "fig,ax = plt.subplots(2,2,figsize=(8,8))\n",
        "\n",
        "for idx, (face_t, att) in enumerate(zip([im_real_face,im_fake_face], atts)):\n",
        "    face_im = ToPILImage()(face_t)\n",
        "    att_img = ToPILImage()(att)\n",
        "    att_img = att_img.resize(face_im.size, resample=Image.NEAREST).convert('RGB')\n",
        "    face_att_img = ImageChops.multiply(face_im, att_img)\n",
        "\n",
        "    ax[idx, 0].imshow(face_im)\n",
        "    ax[idx, 0].set_title('FACE')\n",
        "    ax[idx, 1].imshow(face_att_img)\n",
        "    ax[idx, 1].set_title('ATTENTION')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTMdH959oyGu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycLf0kUZoyGu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}